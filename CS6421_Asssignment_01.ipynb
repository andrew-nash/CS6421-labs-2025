{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GHI8oLVYcolR"
   },
   "source": [
    "# Assignment 1- Topics From Labs 1 & 2\n",
    "  <a target=\"_blank\" href=\"https://colab.research.google.com/github/andrew-nash/CS6421-labs-2025/blob/main/CS6421_Assignment_01.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "Due on  20/02/2025 at 23:59:59 UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MjbPNQP8ddI6"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcE3zaaZ5F8o"
   },
   "source": [
    "# Data Loading And Cleaning\n",
    "\n",
    "For this lab, we will use a house pricing dataset (credit: https://www.kaggle.com/datasets/shree1992/housedata). However, instead of predicting house prices here, we are instead going to attempt to classity to condition of the property based on the other featues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iz_5wMunvFi0"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget -O data.csv https://github.com/andrew-nash/CS6421-labs-2025/raw/refs/heads/main/data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mjoxz44ScZ4v"
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lU_CawCwxMWn"
   },
   "outputs": [],
   "source": [
    "def get_seed_from_s_no(s_no):\n",
    "  ### DO NOT CHANGE THIS FUNCION\n",
    "  seeds = [[16, 81], [30, 18]]\n",
    "  i = int(student_no%2==0)\n",
    "  j = int(student_no%10<5)\n",
    "  return seeds[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QhOx966BvQrY"
   },
   "outputs": [],
   "source": [
    "features = [\"price\",\"bedrooms\",\"bathrooms\",\"sqft_living\",\"sqft_lot\",\"floors\",\"waterfront\",\"view\",\"sqft_above\",\t\"sqft_basement\",\t\"yr_built\",\t\"yr_renovated\"]\n",
    "\n",
    "reduced_data = raw_data[features+['condition']]\n",
    "\n",
    "# enter your student number here\n",
    "student_no = STUDENT NUMBER\n",
    "\n",
    "df = raw_data.sample(axis=1,frac=1, random_state=get_seed_from_s_no(student_no))\n",
    "\n",
    "train_split = 0.85\n",
    "\n",
    "x_train = df[features].to_numpy()[:int(train_split*len(df))]\n",
    "y_train = df['condition'].to_numpy()[:int(train_split*len(df))]\n",
    "\n",
    "x_test = df[features].to_numpy()[int(train_split*len(df)):]\n",
    "y_test = df['condition'].to_numpy()[int(train_split*len(df)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vTeyc_l13sMa"
   },
   "outputs": [],
   "source": [
    "# scaling the x valuee to [0,1] on each column\n",
    "# is done as follows\n",
    "# axis=0 means that the operation is performed accross each column\n",
    "x_train_clean = (x_train-x_train.min(axis=0))/x_train.max(axis=0)\n",
    "\n",
    "#### IMPORTATNT - observe that we scale by _train.min()\n",
    "# when we are scaling the test dataset - why is this?\n",
    "x_test_clean = (x_test-x_train.min(axis=0))/x_train.max(axis=0)\n",
    "\n",
    "### Convert the y data to one hot encoding.\n",
    "### There are 5 values for condition: 1,2,3,4,5\n",
    "###\n",
    "### If we want to use the tf.one_hot function then\n",
    "### convert these to 0,1,2,3,4\n",
    "\n",
    "y_train_clean = tf.one_hot(y_train-1, depth=5)\n",
    "y_test_clean  = tf.one_hot(y_test-1, depth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HrQQ_2kq-4vJ"
   },
   "source": [
    "\n",
    "# Task 1: Hyper-parameter Optimzation\n",
    "\n",
    "We will use the Keras tuner to partially automate this process (https://www.tensorflow.org/tutorials/keras/keras_tuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7XTo6opAOy9"
   },
   "source": [
    "### Model Builder Function\n",
    "\n",
    "The first step is to define a function over the hyper-parameters of interest, that returns the validation metrics.\n",
    "\n",
    "We will then search over these arguments to find their optimal values.\n",
    "\n",
    "For this task, you should search over the following hyper-parameters\n",
    "\n",
    "\n",
    "| Hyper-Parameter | Min | Max |\n",
    "| -- | -- | -- |\n",
    "| No. Layers | 2 | 10 |\n",
    "| Neurons in layer `i` | 10 | 750 |\n",
    "| Regularization | 0.0001 | 0.1 |\n",
    "\n",
    "<br>\n",
    "\n",
    "| Hyper-Parameter | Choices |\n",
    "|---|---|\n",
    "| Activaiton | [relu, elu, sigmoid]|\n",
    "| Type of Regularization | [L1,L2,L1L2] |\n",
    "| Use BatchNorm | [True, False] |\n",
    "| batch_size | [16,64,124] |\n",
    "| Learning Rate | [0.01,0.001,0.001] |\n",
    "| kernel_initializer |  [\"glorot_normal\",\"glorot_uniform\", \"zeros\"] |\n",
    "| bias_initializer |  [\"zeros\", \"ones√ü\"] |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PDmFSeI3Cqi5"
   },
   "outputs": [],
   "source": [
    "!pip install -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pyo0RYS8H7nn"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zG4ghsYRCnRE"
   },
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7797hI-Cc2R"
   },
   "outputs": [],
   "source": [
    "def task1_search_model_coarse(hp):\n",
    "  model = tf.keras.models.Sequential()\n",
    "\n",
    "  model.add(tf.keras.layers.Input(shape=(12,)))\n",
    "\n",
    "  num_layers = hp.Int(\"num_layers\", min_value=2, max_value=10, step=2)\n",
    "  reg_type = hp.Choice(\"reg_type\", [\"L1\", \"L2\", \"L1L2\"])\n",
    "  reg_level = hp.Choice(\"reg_level\", [0.0001, 0.001, 0.01, 0.1])\n",
    "\n",
    "  act_fuc = hp.Choice(\"act_fuc\", [\"relu\", \"elu\", \"sigmoid\"])\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    neurons = hp.Int(f\"num_neurons_layer_{i}\", min_value=10, max_value=750, step=2, sampling='log')\n",
    "\n",
    "    if reg_type == \"L1\":\n",
    "      reg = tf.keras.regularizers.L1(l1=reg_level)\n",
    "    elif reg_type == \"L2\":\n",
    "      reg = tf.keras.regularizers.L2(l2=reg_level)\n",
    "    else:\n",
    "      reg = tf.keras.regularizers.L1L2(l1=reg_level, l2=reg_level)\n",
    "\n",
    "    kernel_initializer = hp.Choice(\"kernel_initializer\", [\"glorot_normal\",\"glorot_uniform\", \"zeros\"])\n",
    "    bias_initializer = hp.Choice(\"bias_initializer\", [\"zeros\", \"ones\"])\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(neurons, activation=act_fuc,\n",
    "                                    activity_regularizer = reg,\n",
    "                                    kernel_initializer=kernel_initializer,\n",
    "                                    bias_initializer=bias_initializer))\n",
    "\n",
    "    add_batchnorm = hp.Boolean(\"add_batchnorm\")\n",
    "    if add_batchnorm:\n",
    "      model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "  model.add(tf.keras.layers.Dense(5, activation=\"softmax\"))\n",
    "\n",
    "  lr = hp.Choice(\"learning_rate\", values=[0.01, 0.001, 0.0001])\n",
    "\n",
    "  model.compile(\n",
    "    optimizer= tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    "  )\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3rO1oRqdufs"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bFWfnKKsBcKT"
   },
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(task1_search_model_coarse,\n",
    "                        objective='val_accuracy',\n",
    "                        max_trials=60,\n",
    "                        seed=42,\n",
    "                        overwrite=True,\n",
    "                        directory=\"./hyp_searches/\",\n",
    "                        project_name=\"coarse_search_bs16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VosAlmeDFKCB"
   },
   "outputs": [],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oy909s8eRZMD"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir \"./hyp_searches/coarse_search_bs16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RiGjDYQhKmCe"
   },
   "outputs": [],
   "source": [
    "tuner.search(\n",
    "    x_train_clean,\n",
    "    y_train_clean,\n",
    "\n",
    "    validation_split = 0.8,\n",
    "    batch_size=16,\n",
    "    epochs=10,\n",
    "    callbacks=[tf.keras.callbacks.TensorBoard(\"./hyp_searches/coarse_search_bs16/tb_logs\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBGt4Im9jarx"
   },
   "outputs": [],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WyQPZ1NXNAGM"
   },
   "source": [
    "### Search Over other Values of batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-7Wih3H-M1Ek"
   },
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(task1_search_model_coarse,\n",
    "                        objective='val_accuracy',\n",
    "                        max_trials=60,\n",
    "                        seed=42,\n",
    "                        overwrite=True,\n",
    "                        directory=\"./hyp_searches/\",\n",
    "                        project_name=\"coarse_search_bs64\")\n",
    "\n",
    "tuner.search(\n",
    "    x_train_clean,\n",
    "    y_train_clean,\n",
    "    validation_split = 0.8,\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    "    callbacks=[tf.keras.callbacks.TensorBoard(\"./hyp_searches/coarse_search_bs64/tb_logs\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rB73QDYDM1sq"
   },
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(task1_search_model_coarse,\n",
    "                        objective='val_accuracy',\n",
    "                        max_trials=60,\n",
    "                        seed=42,\n",
    "                        overwrite=True,\n",
    "                        directory=\"./hyp_searches/\",\n",
    "                        project_name=\"coarse_search_bs124\")\n",
    "tuner.search(\n",
    "    x_train_clean,\n",
    "    y_train_clean,\n",
    "    validation_split = 0.8,\n",
    "    batch_size=124,\n",
    "    epochs=10,\n",
    "    callbacks=[tf.keras.callbacks.TensorBoard(\"./hyp_searches/coarse_search_bs124/tb_logs\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4RLpBQ6Pkdc"
   },
   "source": [
    "### Continue Optimizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQMiwjrMNeAE"
   },
   "source": [
    "Continue tuning this model.\n",
    "\n",
    "**IMPORTANT** Marks will be awarded based on your model-tuning process. Make sure all model builder function names start with `task1_search_`\n",
    "\n",
    "Based on the TensorBoard output above, you should be able to fix a few of the hyper-parameters (hint: such as the activation function).\n",
    "\n",
    "Continue to perform additional hyper-parameter searches to narrow in on the optimal set of hyper-parameters. From the table above.\n",
    "\n",
    "Don't just focus on taking the best validation accuracy - look at the TensorBoard outputs and try to find models that have good performance, but also minimal overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPip9VYMFXQ-"
   },
   "source": [
    "#### Evaluate\n",
    "\n",
    "It is good practice when tuning these hyper-parameters to not use the test dataset for tuning - we will perform a separate split on our training data, and evaluate on the test dataset post-optimization\n",
    "\n",
    "\n",
    "Once you are happy, define a Sequential model using the best parametrs extracted above.\n",
    "\n",
    "Train it for 20 epochs (or fewer if you wish) and evalue its performance on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NU6VxMeUPrTr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOwGaC3IVnYq"
   },
   "source": [
    "### Discussion\n",
    "\n",
    "Explain, in a **short paragraph**\n",
    "\n",
    "1. Some key observations you made in the hyper-parameter tuning.\n",
    "2. If the evalutation on the test datset gave the results you expected, and why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cnlQmCjbVnRO"
   },
   "outputs": [],
   "source": [
    "task1_explanation = '''\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ae1uZhOxzgKH"
   },
   "source": [
    "## Task 2\n",
    "\n",
    "Now, consider that unlike our image labels in the MNIST problems, the labels here are in fact ordinal data, existing on a discrete scale from 1-5.\n",
    "\n",
    "### Re-process The Label Data to Prepare for a model that will predict a single value\n",
    "\n",
    "Instead of one-hot encoding, now we must scale the y_train values (from [1,5]) to be between [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ndpRs2S7WpHl"
   },
   "outputs": [],
   "source": [
    "y_train_clean = None\n",
    "y_test_clean = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTmtfkcA-vHP"
   },
   "source": [
    "### Define a Custom Accruacy Function\n",
    "\n",
    "Since our model predicts a single scalar value to predict discrete ordinal classes, TensorFlow cannot directly assign a class to a prediction itself.\n",
    "\n",
    "The loss can still be computed as normal, but it means that we will need to define the accuracy metric ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T64p5nTaODT-"
   },
   "source": [
    "\\begin{equation}\n",
    "  f_\\text{acc}(y_\\text{true},y_\\text{pred})=   \n",
    "  \\begin{cases}\n",
    "  1& \\text{if}\\; round( 5* y_\\text{true})=round( 5* y_\\text{pred}) \\\\\n",
    "  0& \\text{otherwise}\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "Hint: use the tf.math.round() and tf.equal()\n",
    "function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SNKFWP88_NCZ"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def accuracy(y_true, y_pred):\n",
    "  '''\n",
    "  process\n",
    "  '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6YatDNb0KZe"
   },
   "source": [
    "### Optimize the hyper-parameters Similarly To task 1\n",
    "\n",
    "You do not start from scratch, use a range of hyper-parameters that are close to the optimal values found in task 1.\n",
    "\n",
    "\n",
    "**REMEMBER** that you must change the **output layer** from 12 to 1 neuron, and change the **loss function**. Also, think about what activation function is most appropiate for this output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nCVnK2qpamCK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJusUipF0PZQ"
   },
   "source": [
    "## Compare the models from Task 1 and Task 2\n",
    "\n",
    "Which is better, and why do you think this is the case? Are these results what you expected? Explain in no more than 10 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZDBajuTF9le"
   },
   "outputs": [],
   "source": [
    "final_explanation =  '''\n",
    "  Put your explanation here\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
